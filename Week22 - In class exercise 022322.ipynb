{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d2c456a",
   "metadata": {},
   "source": [
    "# Week 22 - In class exercise\n",
    "## Webscraping in Python\n",
    "### February 23, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dbd6db",
   "metadata": {},
   "source": [
    "**1. Use Splinter and/or Beautiful Soup to scrape mercadolibre.com.mx or soundcloud.com or tripadvisor.com. You must programmatically click a link from the front page to go to another page of interest to you and then select at least 5 items from that page. The 5 items must be stored in a data structure that makes sense (dictionary, list, etc).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62c3f426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import requests\n",
    "\n",
    "# Sound cloud url\n",
    "url='http://soundcloud.com/'\n",
    "\n",
    "# get page response \n",
    "response = requests.get(url)\n",
    "response # yay! successful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8553eb",
   "metadata": {},
   "source": [
    "Create the chrome browser in a new window for us to inspect our work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b4047b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Could not get version for google-chrome with the command:  powershell \"$ErrorActionPreference='silentlycontinue' ; (Get-Item -Path \"$env:PROGRAMFILES\\Google\\Chrome\\Application\\chrome.exe\").VersionInfo.FileVersion ; if (-not $? -or $? -match $error) { (Get-Item -Path \"$env:PROGRAMFILES(x86)\\Google\\Chrome\\Application\\chrome.exe\").VersionInfo.FileVersion } if (-not $? -or $? -match $error) { (Get-Item -Path \"$env:LOCALAPPDATA\\Google\\Chrome\\Application\\chrome.exe\").VersionInfo.FileVersion } if (-not $? -or $? -match $error) { reg query \"HKCU\\SOFTWARE\\Google\\Chrome\\BLBeacon\" /v version } if (-not $? -or $? -match $error) { reg query \"HKLM\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\Google Chrome\" /v version }\"\n",
      "Current google-chrome version is UNKNOWN\n",
      "Get LATEST chromedriver version for UNKNOWN google-chrome\n",
      "Trying to download new driver from https://chromedriver.storage.googleapis.com/98.0.4758.102/chromedriver_win32.zip\n",
      "Driver has been saved in cache [C:\\Users\\artol\\.wdm\\drivers\\chromedriver\\win32\\98.0.4758.102]\n"
     ]
    }
   ],
   "source": [
    "# executable path for a chrome driver\n",
    "executable_path = {'executable_path':ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False) # False, so that it opens a browser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e01f903",
   "metadata": {},
   "source": [
    "After visiting the home page, I used the Developer tools to highlight the button that says \"Explore trending playlists.\" I saw that the href for that element is called \"/home\". I tried to find links by partial href, using that string and it brought my browser to the desired page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f6eae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the soundcloud url in our browser\n",
    "browser.visit(url)\n",
    "\n",
    "# Parse the html code of the page\n",
    "soup = bs(browser.html, 'html.parser')\n",
    "\n",
    "# Click the desired link to bring us to the \"discover\" page\n",
    "browser.links.find_by_partial_href('/home').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae07302",
   "metadata": {},
   "source": [
    "Once I got to the discover page that I wanted, I checked the developer tools again. I wanted to capture the genres in the top 50 charts. To do that, I did ctr+shit+c over the element to view its html location. Because it was so deep into the page, I did a right-click to copy the full xpath. I did this for the first few genres and noticed there was only one element consistently changing. This is the element I iterated over through the f string below.\n",
    "\n",
    "Next, I extracted the text, saved that as a variable, and appended the variable to an empty list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c83043f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 genres: ['All music genres', 'Hip-hop & Rap', 'Pop', 'R&B & Soul', 'Global Beats']\n"
     ]
    }
   ],
   "source": [
    "# Empty list to append our 5 items\n",
    "top_5_genres = []\n",
    "\n",
    "# Create the range for top 5\n",
    "for i in range(1,6):\n",
    "    # iterate through the xpath and extract the text\n",
    "    genre = browser.find_by_xpath(f'//*[@id=\"content\"]/div/div/div[1]/div[3]/div/ul/li[1]/div/div[2]/div[1]/div/div/div[{i}]/div/div[2]/a').text\n",
    "    # append values to list\n",
    "    top_5_genres.append(genre)\n",
    "\n",
    "print(f'Top 5 genres: {top_5_genres}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1335cbef",
   "metadata": {},
   "source": [
    "**2. Share with your group how web scraping worked on the website and link you chose. Compare it with others. List the site you chose and two observations about parsing the website. Indicate if this was the same or different for the sites chosen by others.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3783a752",
   "metadata": {},
   "source": [
    "I chose SoundCloud website, and I observed that many of the desired items (e.g. top charts) are burried very deep into the html code. This can make the elements very tricky to extract. I found that using the ctrl+shit+c shortcut to navigate to the html code and then copying the xpath was the simplest option. I also observed that I was unable to extract some of the later charts (e.g. chart # 40) through the xpath method. I used the same code with the copy&pasted xpath, just to experiment, and it kept returning blank values. Because I am copying the exact xpath in that scenario (rather than iterating through like above), I am unclear on why that would not work. I am wondering if it has something to do with the carousel webflow design of the top 50 charts. On my own, I might try to experiment with the slide forward button on that page to see if that helps.\n",
    "\n",
    "Everyone in my group chose Soundcloud, and a few other people I chatted with via Slack chose SoundCloud as well. However, one person I chatted with had a pretty different approach. Rather than use the xpath, they ended up using a re.search() to find the specific type of element they wanted. I thought that was an interesting solution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
